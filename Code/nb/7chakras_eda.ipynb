{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d14835d",
   "metadata": {},
   "source": [
    "\n",
    "# 7 Chakras Festival 2026 — Exploratory Data Analysis (EDA)\n",
    "\n",
    "Questo notebook analizza il file esportato dei biglietti e costruisce alcune statistiche utili (vendite, entrate, paesi/città, tipi di ticket, sconti, duplicati, ecc.).  \n",
    "**Percorso predefinito del dataset:**\n",
    "\n",
    "```\n",
    "C:\\Users\\spina\\Documents\\Other_Codes\\7chackras\\Documenti\\ticket2026.csv\n",
    "```\n",
    "\n",
    "> Nota: I dati contengono informazioni personali. Usa e condividi questo notebook con attenzione.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0320c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Setup ===================================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# Visual options\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "# Percorso del file CSV (modifica se necessario)\n",
    "CSV_PATH = r\"C:\\Users\\spina\\Documents\\Other_Codes\\7chackras\\Documenti\\ticket2026.csv\"\n",
    "\n",
    "# Cartella di output locale per file puliti / grafici\n",
    "OUTPUT_DIR = os.path.join(os.path.dirname(CSV_PATH), \"eda_outputs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"CSV_PATH:\", CSV_PATH)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50476cd",
   "metadata": {},
   "source": [
    "## 1) Caricamento dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d052ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Proviamo un read_csv robusto per caratteri speciali e virgolette\n",
    "read_kwargs = dict(\n",
    "    sep=\",\",\n",
    "    quotechar='\"',\n",
    "    encoding=\"utf-8\",\n",
    "    engine=\"python\",\n",
    "    dtype=str,   # carichiamo come stringhe per evitare conversioni sbagliate\n",
    "    skip_blank_lines=True\n",
    ")\n",
    "\n",
    "df_raw = pd.read_csv(CSV_PATH, **read_kwargs)\n",
    "print(\"Shape iniziale:\", df_raw.shape)\n",
    "df_raw.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51ecef",
   "metadata": {},
   "source": [
    "## 2) Pulizia colonne e normalizzazione tipi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da087850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.1) Normalizza i nomi colonna: rimuovi spazi, doppi spazi e uniforma duplicati\n",
    "def normalize_col(c):\n",
    "    # strip, collassa spazi, togli spazi finali e punteggiatura ridondante\n",
    "    c = (c or \"\").strip()\n",
    "    c = \" \".join(c.split())  # collapse spaces\n",
    "    return c\n",
    "\n",
    "cols = [normalize_col(c) for c in df_raw.columns]\n",
    "\n",
    "# Deduplica i nomi uguali aggiungendo un suffisso progressivo\n",
    "seen = {}\n",
    "new_cols = []\n",
    "for c in cols:\n",
    "    if c not in seen:\n",
    "        seen[c] = 0\n",
    "        new_cols.append(c)\n",
    "    else:\n",
    "        seen[c] += 1\n",
    "        new_cols.append(f\"{c}__{seen[c]}\")  # es: \"Phone number ...__1\"\n",
    "\n",
    "df = df_raw.copy()\n",
    "df.columns = new_cols\n",
    "\n",
    "print(\"Numero colonne:\", len(df.columns))\n",
    "print(\"Esempio colonne:\\n\", df.columns[:25].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.2) Conversioni utili di tipo\n",
    "\n",
    "# Colonna data pagamento (diversi formati locali: \"31/10/2025 - 07:57\")\n",
    "def parse_payment_date(s):\n",
    "    if pd.isna(s): \n",
    "        return pd.NaT\n",
    "    s = str(s).replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "    s = s.strip()\n",
    "    # Prova formati più comuni italiani/europei\n",
    "    for fmt in [\"%d/%m/%Y - %H:%M\", \"%d/%m/%Y %H:%M\", \"%d/%m/%Y\", \"%d-%m-%Y %H:%M\"]:\n",
    "        try:\n",
    "            return datetime.strptime(s, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT\n",
    "\n",
    "if \"Payment Date\" in df.columns:\n",
    "    df[\"Payment_Date_parsed\"] = df[\"Payment Date\"].map(parse_payment_date)\n",
    "else:\n",
    "    df[\"Payment_Date_parsed\"] = pd.NaT\n",
    "\n",
    "# Converte campi numerici potenzialmente stringa in float\n",
    "def to_num(x):\n",
    "    if x is None or (isinstance(x,float) and np.isnan(x)) or str(x).strip()==\"\" or str(x).strip().lower()==\"nan\":\n",
    "        return np.nan\n",
    "    s = str(x).strip().replace(\"€\",\"\").replace(\",\",\"\").replace(\" \", \"\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        # prova con virgola decimale\n",
    "        s2 = str(x).strip().replace(\"€\",\"\").replace(\".\", \"\").replace(\",\", \".\").replace(\" \", \"\")\n",
    "        try:\n",
    "            return float(s2)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "num_candidates = [\"Order Total\",\"Ticket Subtotal\",\"Ticket Discount\",\"Ticket Fee\",\"Ticket Total\",\"Price\"]\n",
    "for c in num_candidates:\n",
    "    if c in df.columns:\n",
    "        df[c+\"_num\"] = df[c].map(to_num)\n",
    "\n",
    "# Normalizza email (minuscolo/strip) per dedupliche\n",
    "for c in [\"Attendee E-mail\",\"Buyer E-Mail\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(str).str.strip().str.lower()\n",
    "\n",
    "print(df[[\"Payment Date\",\"Payment_Date_parsed\"]].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Salva una copia \"pulita\" per usi futuri\n",
    "clean_path = os.path.join(OUTPUT_DIR, \"tickets_clean.csv\")\n",
    "df.to_csv(clean_path, index=False, encoding=\"utf-8\")\n",
    "print(\"Salvato:\", clean_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9856fdc9",
   "metadata": {},
   "source": [
    "## 3) Panoramica rapida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_rows, n_cols = df.shape\n",
    "print(f\"Righe (record biglietti): {n_rows:,}\")\n",
    "print(f\"Colonne: {n_cols:,}\")\n",
    "\n",
    "# Campi chiave disponibili\n",
    "key_fields = [c for c in [\n",
    "    \"Event Name\",\"Order Number\",\"Order Status\",\"Payment Date\",\"Payment_Date_parsed\",\n",
    "    \"Attendee E-mail\",\"Buyer E-Mail\",\"Ticket Type\",\"Ticket Code\",\"Ticket ID\",\n",
    "    \"Ticket Total_num\",\"Order Total_num\",\"Price_num\",\"Discount Code\",\n",
    "    \"Country of residence / Paese di residenza (Campi ticket holder)\",\n",
    "    \"City of residence / Città di residenza (Campi ticket holder)\"\n",
    "] if c in df.columns]\n",
    "print(\"\\nCampi chiave:\\n\", key_fields)\n",
    "\n",
    "df[key_fields].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45b562",
   "metadata": {},
   "source": [
    "## 4) Vendite & ricavi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c951fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tot_tickets = len(df)\n",
    "tot_revenue_ticket = df.get(\"Ticket Total_num\", pd.Series(dtype=float)).sum()\n",
    "tot_revenue_order = df.get(\"Order Total_num\", pd.Series(dtype=float)).sum()\n",
    "avg_ticket_price = df.get(\"Ticket Total_num\", pd.Series(dtype=float)).mean()\n",
    "\n",
    "print(f\"Totale biglietti: {tot_tickets:,}\")\n",
    "print(f\"Somma Ticket Total (€): {tot_revenue_ticket:,.2f}\")\n",
    "print(f\"Somma Order Total (€):  {tot_revenue_order:,.2f}\")\n",
    "print(f\"Prezzo medio per riga (Ticket Total): {avg_ticket_price:,.2f} €\")\n",
    "\n",
    "# Vendite per tipo di ticket\n",
    "by_type = df.groupby(\"Ticket Type\", dropna=False).agg(\n",
    "    tickets=(\"Ticket Type\",\"size\"),\n",
    "    revenue=(\"Ticket Total_num\",\"sum\"),\n",
    "    avg_price=(\"Ticket Total_num\",\"mean\")\n",
    ").sort_values([\"revenue\",\"tickets\"], ascending=False)\n",
    "by_type.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6919b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grafico: ticket per tipo\n",
    "counts = by_type[\"tickets\"]\n",
    "plt.figure(figsize=(10,5))\n",
    "counts.plot(kind=\"bar\")\n",
    "plt.title(\"Conteggio biglietti per 'Ticket Type'\")\n",
    "plt.ylabel(\"Biglietti\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a2dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Timeline vendite: biglietti per giorno (basata su Payment_Date_parsed)\n",
    "ts = df.dropna(subset=[\"Payment_Date_parsed\"]).copy()\n",
    "if not ts.empty:\n",
    "    ts[\"date\"] = ts[\"Payment_Date_parsed\"].dt.date\n",
    "    daily = ts.groupby(\"date\").size()\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    daily.plot(kind=\"line\", marker=\"o\")\n",
    "    plt.title(\"Biglietti venduti per giorno\")\n",
    "    plt.xlabel(\"Data\")\n",
    "    plt.ylabel(\"Biglietti\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Cumulata\n",
    "    plt.figure(figsize=(10,4))\n",
    "    daily.cumsum().plot(kind=\"line\", marker=\"o\")\n",
    "    plt.title(\"Biglietti cumulati nel tempo\")\n",
    "    plt.xlabel(\"Data\")\n",
    "    plt.ylabel(\"Cumulato biglietti\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Nessuna data di pagamento valida per costruire una timeline.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ca150",
   "metadata": {},
   "source": [
    "## 5) Provenienza geografica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c6bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "country_col = \"Country of residence / Paese di residenza (Campi ticket holder)\"\n",
    "city_col    = \"City of residence / Città di residenza (Campi ticket holder)\"\n",
    "\n",
    "if country_col in df.columns:\n",
    "    by_country = df.groupby(country_col, dropna=False).size().sort_values(ascending=False)\n",
    "    print(\"Top paesi:\\n\", by_country.head(20))\n",
    "    plt.figure(figsize=(10,4))\n",
    "    by_country.head(15).plot(kind=\"bar\")\n",
    "    plt.title(\"Top paesi (prime 15 voci)\")\n",
    "    plt.ylabel(\"Biglietti\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if city_col in df.columns:\n",
    "    by_city = df.groupby(city_col, dropna=False).size().sort_values(ascending=False)\n",
    "    print(\"Top città:\\n\", by_city.head(20))\n",
    "    plt.figure(figsize=(10,4))\n",
    "    by_city.head(15).plot(kind=\"bar\")\n",
    "    plt.title(\"Top città (prime 15 voci)\")\n",
    "    plt.ylabel(\"Biglietti\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd7536",
   "metadata": {},
   "source": [
    "## 6) Codici sconto & scontistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a71a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"Discount Code\" in df.columns:\n",
    "    has_disc = df[\"Discount Code\"].fillna(\"\").str.strip() != \"\"\n",
    "    n_disc = has_disc.sum()\n",
    "    print(f\"Righe con codice sconto: {n_disc} ({n_disc/len(df)*100:.1f}%)\")\n",
    "\n",
    "    disc_counts = df.loc[has_disc, \"Discount Code\"].value_counts()\n",
    "    print(\"\\nFrequenza per codice sconto:\\n\", disc_counts)\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    disc_counts.plot(kind=\"bar\")\n",
    "    plt.title(\"Frequenza codici sconto\")\n",
    "    plt.ylabel(\"Occorrenze\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Sconto medio (se 'Ticket Discount_num' presente)\n",
    "    if \"Ticket Discount_num\" in df.columns:\n",
    "        avg_disc = df.loc[has_disc, \"Ticket Discount_num\"].mean()\n",
    "        print(f\"\\nSconto medio (solo righe con sconto): {avg_disc:.2f} €\")\n",
    "else:\n",
    "    print(\"Colonna 'Discount Code' non presente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd00c68",
   "metadata": {},
   "source": [
    "## 7) Check-in (se disponibili)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0157f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alcune esportazioni hanno colonne: 'Checked-in', 'Check-ins', 'Check-outs'\n",
    "for c in [\"Checked-in\",\"Check-ins\",\"Check-outs\"]:\n",
    "    if c in df.columns:\n",
    "        print(c, \"— esempi:\", df[c].dropna().unique()[:10])\n",
    "\n",
    "if \"Checked-in\" in df.columns:\n",
    "    checked = df[\"Checked-in\"].str.strip().str.lower()\n",
    "    counts = checked.value_counts(dropna=False)\n",
    "    print(\"\\nStato 'Checked-in':\\n\", counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9698b64",
   "metadata": {},
   "source": [
    "## 8) Duplicati & qualità dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6fa5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Potenziali duplicati per email partecipante\n",
    "dup_att = []\n",
    "if \"Attendee E-mail\" in df.columns:\n",
    "    vc = df[\"Attendee E-mail\"].value_counts()\n",
    "    dup_att = vc[vc>1]\n",
    "    print(\"Email (Attendee) con più di un record:\", len(dup_att))\n",
    "    display(dup_att.head(20))\n",
    "\n",
    "# Potenziali duplicati per Order Number\n",
    "if \"Order Number\" in df.columns:\n",
    "    vc_ord = df[\"Order Number\"].value_counts()\n",
    "    multi_in_order = vc_ord[vc_ord>1]\n",
    "    print(\"\\nOrdini con più di una riga:\", len(multi_in_order))\n",
    "    display(multi_in_order.head(20))\n",
    "\n",
    "# Campi mancanti su colonne chiave\n",
    "key_miss_cols = [c for c in [\"Attendee E-mail\",\"Buyer E-Mail\",\"Order Number\",\"Ticket Type\",\"Ticket Total_num\"] if c in df.columns]\n",
    "missing_summary = df[key_miss_cols].isna().mean().sort_values(ascending=False)\n",
    "print(\"\\n% Valori mancanti su campi chiave:\\n\", (missing_summary*100).round(1))\n",
    "\n",
    "# Righe sospette (prezzo zero ma stato 'Paid', ecc.)\n",
    "sus = df[(df.get(\"Ticket Total_num\", pd.Series(dtype=float)).fillna(0)==0) & (df.get(\"Order Status\", \"\").astype(str).str.lower()==\"paid\")]\n",
    "print(f\"\\nRighe con Ticket Total zero ma ordine 'Paid': {len(sus)}\")\n",
    "if len(sus)>0:\n",
    "    display(sus[[\"Order Number\",\"Order Status\",\"Ticket Total\",\"Ticket Total_num\",\"Discount Code\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2845ca",
   "metadata": {},
   "source": [
    "## 9) Esportazioni riassuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Salva alcune tabelle utili\n",
    "exports = {}\n",
    "\n",
    "if \"Ticket Type\" in df.columns:\n",
    "    exports[\"by_type.csv\"] = df.groupby(\"Ticket Type\", dropna=False).agg(\n",
    "        tickets=(\"Ticket Type\",\"size\"),\n",
    "        revenue=(\"Ticket Total_num\",\"sum\"),\n",
    "        avg_price=(\"Ticket Total_num\",\"mean\")\n",
    "    ).sort_values([\"revenue\",\"tickets\"], ascending=False)\n",
    "\n",
    "country_col = \"Country of residence / Paese di residenza (Campi ticket holder)\"\n",
    "if country_col in df.columns:\n",
    "    exports[\"by_country.csv\"] = df.groupby(country_col, dropna=False).size().to_frame(\"tickets\").sort_values(\"tickets\", ascending=False)\n",
    "\n",
    "for name, tab in exports.items():\n",
    "    outp = os.path.join(OUTPUT_DIR, name)\n",
    "    tab.to_csv(outp, encoding=\"utf-8\")\n",
    "    print(\"Esportato:\", outp)\n",
    "\n",
    "print(\"\\nFatto!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d38614",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Suggerimenti\n",
    "- Se alcune colonne hanno lo stesso nome (es. campi ripetuti per più ticket holder), sono state rinominate con suffissi `__1`, `__2`, ecc.\n",
    "- Per analisi avanzate (es. validazione Codice Fiscale), puoi aggiungere celle dedicate.\n",
    "- Per una segmentazione per **fase prezzo** puoi usare `Ticket Type` (contiene \"PHASE 0\", \"PHASE 1\", ecc.).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
